{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab0c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f691ab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ishap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "tokenizer = TweetTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                           \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e89ea819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy Asoka Jayanti to all who celebrate! Let'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theres national shock when police fired water ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I just joined Standing For Women. One of the m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Hollywood tour includes this monument?\\n#...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fellow Kenyans, we must remember that without ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>#Pakistan don't have red line . Terrorists blo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>A lot of the time people forget that enslaved ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Where are the European chads who just leave lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>“Mainstream media and the political class shru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>The statement of the Federal Interior Minister...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  class\n",
       "0    Happy Asoka Jayanti to all who celebrate! Let'...      2\n",
       "1    Theres national shock when police fired water ...      0\n",
       "2    I just joined Standing For Women. One of the m...      0\n",
       "3    What Hollywood tour includes this monument?\\n#...      1\n",
       "4    Fellow Kenyans, we must remember that without ...      2\n",
       "..                                                 ...    ...\n",
       "837  #Pakistan don't have red line . Terrorists blo...      0\n",
       "838  A lot of the time people forget that enslaved ...      0\n",
       "839  Where are the European chads who just leave lo...      0\n",
       "840  “Mainstream media and the political class shru...      0\n",
       "841  The statement of the Federal Interior Minister...      0\n",
       "\n",
       "[842 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Tweets.tsv\", sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ee74cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    # Remove mentions and hashtags\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    tweet = tweet.replace('#', '')\n",
    "    # Remove punctuations\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove emojis\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "    # Remove numbers\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
    "    tweet = re.sub(r'[^\\w\\s]+', '', tweet)\n",
    "    # Tokenize the tweet\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Join the tokens to form the preprocessed tweet\n",
    "    preprocessed_tweet = ' '.join(tokens)\n",
    "    return preprocessed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d8378d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy Asoka Jayanti celebrate Lets remember Em...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theres national shock police fired water canno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I joined Standing For Women One mratra violent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Hollywood tour includes monument guncultu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fellow Kenyans must remember without peace not...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Pakistan dont red line Terrorists blowing mosq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>A lot time people forget enslaved people Briti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Where European chads leave lol I see European ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Mainstream media political class shrugged rebe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>The statement Federal Interior Minister open r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  class\n",
       "0    Happy Asoka Jayanti celebrate Lets remember Em...      2\n",
       "1    Theres national shock police fired water canno...      0\n",
       "2    I joined Standing For Women One mratra violent...      0\n",
       "3    What Hollywood tour includes monument guncultu...      1\n",
       "4    Fellow Kenyans must remember without peace not...      2\n",
       "..                                                 ...    ...\n",
       "837  Pakistan dont red line Terrorists blowing mosq...      0\n",
       "838  A lot time people forget enslaved people Briti...      0\n",
       "839  Where European chads leave lol I see European ...      0\n",
       "840  Mainstream media political class shrugged rebe...      0\n",
       "841  The statement Federal Interior Minister open r...      0\n",
       "\n",
       "[842 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = df.iloc[:, 0].apply(preprocess_tweet)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cd7146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Preprocessed_Tweets.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8db4f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame: 588, label proportions: \n",
      "0    0.510204\n",
      "2    0.261905\n",
      "1    0.227891\n",
      "Name: class, dtype: float64\n",
      "Dev DataFrame: 85, label proportions: \n",
      "0    0.517647\n",
      "2    0.258824\n",
      "1    0.223529\n",
      "Name: class, dtype: float64\n",
      "Test DataFrame: 169, label proportions: \n",
      "0    0.508876\n",
      "2    0.266272\n",
      "1    0.224852\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the original DataFrame into train and test DataFrames, keeping equal proportions of labels\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['class'])\n",
    "\n",
    "# Split the train DataFrame further into train and dev DataFrames, keeping equal proportions of labels\n",
    "train_df, dev_df = train_test_split(train_df, test_size=0.125, stratify=train_df['class'])\n",
    "\n",
    "# Print the sizes and label proportions of the three DataFrames\n",
    "print(f'Train DataFrame: {len(train_df)}, label proportions: \\n{train_df[\"class\"].value_counts(normalize=True)}')\n",
    "print(f'Dev DataFrame: {len(dev_df)}, label proportions: \\n{dev_df[\"class\"].value_counts(normalize=True)}')\n",
    "print(f'Test DataFrame: {len(test_df)}, label proportions: \\n{test_df[\"class\"].value_counts(normalize=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c36f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.tsv', sep='\\t', index=False)\n",
    "test_df.to_csv('test.tsv', sep='\\t', index=False)\n",
    "dev_df.to_csv('dev.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
